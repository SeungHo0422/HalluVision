"""
Malwarebytes Crawler for malware information
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.common.exceptions import WebDriverException
from typing import List, Optional
import time


class MalwarebyteCrawler:
    """Malwarebytes blog crawler for malware information"""
    
    def __init__(self, headless: bool = True):
        """
        Initialize Malwarebytes crawler
        
        Args:
            headless (bool): Whether to run browser in headless mode
        """
        self.headless = headless
        self.driver = None
    
    def start_webdriver_session(self):
        """Start a new webdriver session"""
        options = webdriver.ChromeOptions()
        if self.headless:
            options.add_argument("--headless")
        self.driver = webdriver.Chrome(options=options)
        return self.driver
    
    def crawl_malwarebyte(self, search_word: str) -> List[str]:
        """
        Crawl Malwarebytes blog for specific malware information
        
        Args:
            search_word (str): Malware name to search for
            
        Returns:
            List[str]: List of extracted article contents
        """
        if not self.driver:
            self.start_webdriver_session()
        
        results_dict = []
        
        try:
            search_url = f"https://www.malwarebytes.com/blog?s={search_word}"
            self.driver.get(search_url)
            
            # Wait for search results to load
            self.driver.implicitly_wait(3)
            print(f"Searching: {self.driver.current_url}")
            
            # Find search results
            search_results = self.driver.find_elements(By.CLASS_NAME, "content")
            
            # Process each search result
            for result in search_results:
                try:
                    # Find article title and link
                    search_results_title = result.find_element(By.TAG_NAME, "h2").find_element(By.TAG_NAME, "a")
                    print(f"Processing article: {search_results_title.text}")
                    
                    # Click on the article
                    search_results_title.click()
                    self.driver.implicitly_wait(5)
                    
                    article_content = ""
                    
                    try:
                        # Extract article content
                        search_whole_content = self.driver.find_element(By.CLASS_NAME, "post-content")
                        search_results_paragraphs = search_whole_content.find_elements(By.TAG_NAME, "p")
                        
                        for para in search_results_paragraphs:
                            article_content += para.text + " "
                        
                        results_dict.append(article_content.strip())
                        
                        # Go back to search results
                        self.driver.back()
                        self.driver.implicitly_wait(3)
                        
                    except Exception as e:
                        print(f"[ERROR] Failed to extract article content: {e}")
                        self.driver.back()
                        self.driver.implicitly_wait(3)
                        
                except Exception as e:
                    print(f"[ERROR] Failed to process search result: {e}")
                    break
        
        except Exception as e:
            print(f"[ERROR] Failed to search Malwarebytes: {e}")
        
        finally:
            if self.driver:
                self.driver.quit()
        
        return results_dict
    
    def crawl_malwarebytes_category(self, category: str = "malware") -> List[str]:
        """
        Crawl Malwarebytes blog by category
        
        Args:
            category (str): Category to crawl
            
        Returns:
            List[str]: List of article URLs
        """
        if not self.driver:
            self.start_webdriver_session()
        
        article_urls = []
        
        try:
            category_url = f"https://www.malwarebytes.com/blog/category/{category}"
            self.driver.get(category_url)
            self.driver.implicitly_wait(5)
            
            # Find article links
            articles = self.driver.find_elements(By.CSS_SELECTOR, "article h2 a")
            
            for article in articles:
                try:
                    url = article.get_attribute("href")
                    if url:
                        article_urls.append(url)
                except:
                    continue
        
        except Exception as e:
            print(f"[ERROR] Failed to crawl category: {e}")
        
        finally:
            if self.driver:
                self.driver.quit()
        
        return article_urls


# Legacy function for backward compatibility
def crawl_malwarebyte(search_word: str) -> List[str]:
    """
    Legacy wrapper function for MalwarebyteCrawler
    
    Args:
        search_word (str): Malware name to search for
        
    Returns:
        List[str]: List of extracted article contents
    """
    crawler = MalwarebyteCrawler()
    return crawler.crawl_malwarebyte(search_word)


if __name__ == "__main__":
    # Test the crawler
    crawler = MalwarebyteCrawler()
    results = crawler.crawl_malwarebyte("zeus")
    
    print(f"Found {len(results)} articles")
    for i, article in enumerate(results[:2], 1):
        print(f"{i}. {article[:200]}...")
