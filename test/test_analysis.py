#!/usr/bin/env python3
"""
ê¸°ì¡´ LLM ê²°ê³¼ ë°ì´í„°ë¡œ ë¶„ì„ ë° í‰ê°€ í…ŒìŠ¤íŠ¸
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import json
from pathlib import Path
from analyzer.qa_analyzer import QAAnalyzer
from analyzer.visualization import VisualizationManager

def test_qa_analysis():
    """ê¸°ì¡´ ë°ì´í„°ë¡œ QA ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    
    print("="*60)
    print("QA Analysis Test with Existing Data")
    print("="*60)
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    ground_truth_path = "datasets/ground_truth_ner.json"
    llm_results_path = "datasets/llm_results_gpt3.5_turbo_250427.json"
    output_dir = "test_analysis_output"
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    Path(output_dir).mkdir(exist_ok=True)
    
    # QA Analyzer ì´ˆê¸°í™”
    qa_analyzer = QAAnalyzer()
    
    print(f"\n1. ë°ì´í„° ë¡œë”©:")
    print(f"   - Ground Truth: {ground_truth_path}")
    print(f"   - LLM Results: {llm_results_path}")
    
    # ê¸°ì¡´ LLM ê²°ê³¼ ë°ì´í„°ë¥¼ QA ë¶„ì„ í˜•íƒœë¡œ ë³€í™˜
    with open(llm_results_path, 'r', encoding='utf-8') as f:
        llm_data = json.load(f)
    
    # QA ë°ì´í„° í˜•íƒœë¡œ ë³€í™˜ (ì²˜ìŒ 100ê°œë§Œ í…ŒìŠ¤íŠ¸)
    qa_data_for_analysis = []
    max_items = 100  # ì „ì²´ ë°ì´í„°ëŠ” ë„ˆë¬´ í¬ë¯€ë¡œ ì¼ë¶€ë§Œ
    
    for i, item in enumerate(llm_data[:max_items]):
        qa_item = {
            "id": item.get("id"),
            "qa_text": item.get("qa_text", "")
        }
        qa_data_for_analysis.append(qa_item)
    
    print(f"\n2. ë¶„ì„ ì¤€ë¹„:")
    print(f"   - ì²˜ë¦¬í•  QA í•­ëª©: {len(qa_data_for_analysis)}ê°œ")
    print(f"   - ëª¨ë¸ëª…: gpt-3.5-turbo")
    
    # Ground Truth ë°ì´í„° ë¡œë“œ
    with open(ground_truth_path, 'r', encoding='utf-8') as f:
        original_data = json.load(f)
    
    print(f"   - Ground Truth í•­ëª©: {len(original_data)}ê°œ")
    
    print(f"\n3. QA ë¶„ì„ ì‹¤í–‰:")
    try:
        # QA í‰ê°€ ì‹¤í–‰
        qa_results = qa_analyzer.run_full_evaluation(
            original_data,
            qa_data_for_analysis,
            model_name="gpt-3.5-turbo",
            save_failures=True,
            output_dir=output_dir
        )
        
        print(f"   âœ… QA ë¶„ì„ ì™„ë£Œ!")
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        if "metrics" in qa_results:
            metrics = qa_results["metrics"]
            
            if "overall_metrics" in metrics:
                om = metrics["overall_metrics"]
                print(f"\n4. ì „ì²´ ì„±ëŠ¥ ì§€í‘œ:")
                print(f"   - í‰ê·  Precision: {om.get('avg_precision', 0):.4f}")
                print(f"   - í‰ê·  Recall: {om.get('avg_recall', 0):.4f}")
                print(f"   - í‰ê·  F1: {om.get('avg_f1', 0):.4f}")
            
            if "label_metrics" in metrics:
                print(f"\n5. ë¼ë²¨ë³„ ì„±ëŠ¥:")
                for label, label_metrics in metrics["label_metrics"].items():
                    print(f"   - {label}: P={label_metrics.get('precision', 0):.4f}, "
                          f"R={label_metrics.get('recall', 0):.4f}, "
                          f"F1={label_metrics.get('f1', 0):.4f}")
        
        # ì‹¤íŒ¨ ë¶„ì„
        if "failure_analysis" in qa_results:
            failure_analysis = qa_results["failure_analysis"]
            print(f"\n6. ì‹¤íŒ¨ ë¶„ì„:")
            print(f"   - ì´ ì‹¤íŒ¨ í•­ëª©: {failure_analysis.get('total_failures', 0)}ê°œ")
            
            if "common_failure_patterns" in failure_analysis:
                print(f"   - ì£¼ìš” ì‹¤íŒ¨ íŒ¨í„´:")
                for pattern, count in failure_analysis["common_failure_patterns"].items():
                    print(f"     * {pattern}: {count}íšŒ")
        
        # ê²°ê³¼ ì €ì¥
        results_path = Path(output_dir) / "qa_analysis_results.json"
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(qa_results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\n7. ê²°ê³¼ ì €ì¥:")
        print(f"   - ë¶„ì„ ê²°ê³¼: {results_path}")
        print(f"   - ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}/")
        
        return qa_results
        
    except Exception as e:
        print(f"   âŒ QA ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_visualization(qa_results):
    """ì‹œê°í™” í…ŒìŠ¤íŠ¸"""
    
    if not qa_results:
        print("\nâš ï¸  QA ê²°ê³¼ê°€ ì—†ì–´ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    print(f"\n" + "="*60)
    print("Visualization Test")
    print("="*60)
    
    try:
        # ì‹œê°í™” ë§¤ë‹ˆì € ì´ˆê¸°í™”
        visualizer = VisualizationManager("test_analysis_output/figures")
        
        # QA ì„±ëŠ¥ íˆíŠ¸ë§µ
        if "metrics" in qa_results:
            print("\n1. QA ì„±ëŠ¥ íˆíŠ¸ë§µ ìƒì„±...")
            qa_metrics = {"gpt-3.5-turbo": qa_results["metrics"]}
            visualizer.plot_qa_performance_heatmap(
                qa_metrics,
                "test_analysis_output/figures/qa_performance_heatmap.pdf"
            )
            print("   âœ… íˆíŠ¸ë§µ ìƒì„± ì™„ë£Œ")
        
        # ì‹¤íŒ¨ ë¶„ì„ ì‹œê°í™”
        if "failure_analysis" in qa_results:
            print("\n2. ì‹¤íŒ¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„±...")
            failure_analysis = qa_results["failure_analysis"]
            visualizer.plot_failure_analysis(
                failure_analysis,
                "test_analysis_output/figures/failure_analysis.pdf"
            )
            print("   âœ… ì‹¤íŒ¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")
        
        print(f"\n3. ì‹œê°í™” íŒŒì¼:")
        print(f"   - ë””ë ‰í† ë¦¬: test_analysis_output/figures/")
        print(f"   - QA ì„±ëŠ¥ íˆíŠ¸ë§µ: qa_performance_heatmap.pdf")
        print(f"   - ì‹¤íŒ¨ ë¶„ì„: failure_analysis.pdf")
        
    except Exception as e:
        print(f"   âŒ ì‹œê°í™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    
    print("ğŸ“Š ê¸°ì¡´ LLM ê²°ê³¼ ë°ì´í„° ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("ğŸ” gpt-3.5-turbo ê²°ê³¼ì™€ ground truth ë¹„êµ")
    
    # QA ë¶„ì„ í…ŒìŠ¤íŠ¸
    qa_results = test_qa_analysis()
    
    # ì‹œê°í™” í…ŒìŠ¤íŠ¸
    test_visualization(qa_results)
    
    print(f"\n" + "="*60)
    print("âœ… ë¶„ì„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ğŸ“ ê²°ê³¼ëŠ” test_analysis_output/ ë””ë ‰í† ë¦¬ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
    print("="*60)

if __name__ == "__main__":
    main()
